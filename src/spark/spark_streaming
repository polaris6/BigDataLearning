一、从Kafka中读数据的方式
    SparkStreaming基于kafka获取数据的方式主要有两种：Receiver和Direct。
    基于Receiver的方式是使用Kafka的High Level Consumer API高阶API来实现的，为createStream。
    基于Direct的方式是使用Kafka的Low Level Consumer API低阶API来实现的，为createDirectStream。


二、KafkaUtils.createStream
1、介绍：
    Receiver从Kafka中获取的数据都是存储在Spark Executor的内存中的，然后Spark Streaming启动job去处理那些数据。
    在通过Kafka Receiver获取Kafka数据的过程中，这台机器有可能宕机了，如果来不及做备份，数据就会丢失，切换到另外一台机器
上，也没有相关数据。如果要启用高可靠机制，让数据零丢失，就必须启用Spark Streaming的预写日志机制（Write Ahead Log，WAL）。
该机制会同步地将接收到的Kafka数据写入分布式文件系统（比如HDFS）上的预写日志中。所以即使底层节点出现了失败，也可以使用
预写日志中的数据进行恢复。
2、优点：
    不需要自己管理消息的offset，Consumer会将从特定的Partition读到的最后的offset保存至Zookeeper。
3、缺点：
    不能保证Exactly Once，如果启用WAL会导致性能较低，如果不启用可能会丢数据。


三、KafkaUtils.createDirectStream
1、优点：
①、Exactly Once：
    这种方式能保证严格的事务一致性，消息只会被处理一次。基于Direct的方式，使用kafka的低阶api，Spark Streaming自己负责
追踪消费的offset，并保存在checkpoint中。Spark自己一定是同步的，因此可以保证数据仅消费一次。
②、高性能：
    如果要保证数据零丢失，在基于Receiver的方式中，需要开启WAL机制。这种方式效率低下，因为数据实际上被复制了两份，Kafka
自己本身有高可靠的机制，会对数据复制一份，这里又会复制一份到WAL中。基于Direct的方式，不需要开启WAL机制。
③、并行读取：
    Spark会创建跟Kafka Partition一样多的RDD Partition，并且会并行从Kafka中读取数据。所以在Kafka Partition和RDD Partition
之间，有个一对一的映射关系。而Receiver的方式，这两个Partition是没任何关系的。
2、缺点：
    无法使用基于zookeeper的kafka监控工具。